{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 8 - Patterns in Data, Correlation and Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `statsmodels` library\n",
    "\n",
    "The `statsmodels` library for Python is a very popular library which provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration. As an example, in this section, we will use the famous **Boston House dataset**. The `scikit-learn` library comes with this dataset, so you don't need to download it separately. You can also download it from [Kaggle](https://www.kaggle.com/c/boston-housing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing Values in Suburbs of Boston\n",
    "\n",
    "The `medv` variable is the target variable.  \n",
    "\n",
    "#### Data description\n",
    "The Boston data frame has 506 rows and 14 columns. The columns are:\n",
    "\n",
    "- `crim` : per capita crime rate by town.\n",
    "- `zn` : proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- `indus` : proportion of non-retail business acres per town.\n",
    "- `chas` : Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "- `nox` : nitrogen oxides concentration (parts per 10 million).\n",
    "- `rm` : average number of rooms per dwelling.\n",
    "- `age` : proportion of owner-occupied units built prior to 1940.\n",
    "- `dis` : weighted mean of distances to five Boston employment centres.\n",
    "- `rad` : index of accessibility to radial highways.\n",
    "- `tax` : full-value property-tax rate per \\$10,000.\n",
    "- `ptratio` : pupil-teacher ratio by town.\n",
    "- `black` : 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
    "- `lstat` : lower status of the population (percent).\n",
    "- `medv` : median value of owner-occupied homes in $1000s.\n",
    "\n",
    "#### Source\n",
    "> Harrison, D. and Rubinfeld, D.L. (1978) Hedonic prices and the demand for clean air. J. Environ. Economics and Management 5, 81–102.\n",
    "> Belsley D.A., Kuh, E. and Welsch, R.E. (1980) Regression Diagnostics. Identifying Influential Data and Sources of Collinearity. New York: Wiley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Ways to Check the Package Version in Python\n",
    "# to make sure you are staying current\n",
    "\n",
    "#!pip list\n",
    "#!pip show seaborn\n",
    "#!pip show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install statsmodels\n",
    "# %pip install seaborn\n",
    "# %pip install --upgrade seaborn\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below has been deactivated - newer versions of packages no longer support it. Use alternatives (e.g., code in cells below) \n",
    "# data = datasets.load_boston()\n",
    "# print(data.DESCR)\n",
    "\n",
    "# Set the features  \n",
    "# df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Set the target\n",
    "# target = pd.DataFrame(data.target, columns=[\"MEDV\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying linear regression, you will need to prepare the data and segregate <font color=Crimson>the features</font> and <font color=Crimson>the label</font> of the dataset. MEDV (median home value) is the label in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and NumPy import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get Boston Housing data\n",
    "df = pd.read_csv('./data/BostonHousing.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Try some **magic commands**: among the most handy ones are below, while details are [here](https://ipython.readthedocs.io/en/stable/interactive/magics.html).\n",
    "- `%time [you statement or expression]` : time execution of a Python statement or expression\n",
    "- `%who` : contents of the namespace \n",
    "- `%who_ls` : sorted contents of the namespace \n",
    "- `%whos` : like `%who`, but gives some extra information about each variable\n",
    "- `%xdel -var`: delete a variable\n",
    "- `%reset` : resets the namespace by removing all names defined by the user\n",
    "- `%conda install [pkgs]`\n",
    "- `%pip install [pkgs]`\n",
    "- `%lsmagic` : list currently available magic functions\n",
    "- `%precision 3` : set default precision for output (e.g., 3 decimal points)\n",
    "- `%pwd` : return the current working directory path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, in Regression section, we will need $X$ and $y$ variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign MEDV to y variable:\n",
    "y = df[\"MEDV\"]          # Target Variable\n",
    "\n",
    "\n",
    "# Drop MEDV from df and assign the rest to X variable:\n",
    "\n",
    "# Option 1:\n",
    "X = df.drop([\"MEDV\"],axis=1)   # Feature Matrix\n",
    "\n",
    "# Option 2:\n",
    "# X = df.drop(columns=[\"MEDV\"])   # Feature Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pearson Correlation\n",
    "plt.figure(figsize=(12,10))                     # Set figure size\n",
    "cor = df.corr()                                 # Get correlation table\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)   # Plot correlations\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colormaps come from `matplotlib`. Check the documentation at https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html.  \n",
    "\n",
    "- Perceptually Uniform Sequential \n",
    "    - 'viridis', 'plasma', 'inferno', 'magma', 'cividis'\n",
    "- 'Sequential'\n",
    "    - 'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds', 'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu', 'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn'\n",
    "- Sequential (2) \n",
    "    - 'binary', 'gist_yarg', 'gist_gray', 'gray', 'bone', 'pink', 'spring', 'summer', 'autumn', 'winter', 'cool', 'Wistia', 'hot', 'afmhot', 'gist_heat', 'copper'\n",
    "- Diverging \n",
    "    - 'PiYG', 'PRGn', 'BrBG', 'PuOr', 'RdGy', 'RdBu', 'RdYlBu', 'RdYlGn', 'Spectral', 'coolwarm', 'bwr', 'seismic'            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.RdYlGn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "ax = sns.heatmap(\n",
    "    cor, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df), plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many variables to display. We will select only a subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf=df[['MEDV','CRIM','ZN','PTRATIO','CHAS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(subdf,kind=\"scatter\") #kind=\"scatter\" or \"reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MEDV']);plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find older usage of `seaborn` online, e.g., `sn.distplot()` above. The warning indicates that you need to adopt to an updated functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['MEDV'],kde=True,fill=True,bins=30,stat='density');plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Additional examples for a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library & dataset\n",
    "df2 = sns.load_dataset('iris')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without regression\n",
    "sns.pairplot(df2, kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with regression\n",
    "sns.pairplot(df2, kind=\"reg\") # try adding `diag_kind=\"kde\"` or `markers='*'`  or  `diag_kws=dict(fill=False)` \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df2, kind=\"scatter\", hue=\"species\", markers=[\"o\", \"s\", \"D\"], palette=\"Set2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can give other arguments with plot_kws.\n",
    "sns.pairplot(df2, kind=\"scatter\", hue=\"species\", plot_kws=dict(s=80, edgecolor=\"white\", linewidth=2.5)) \n",
    "plt.show()\n",
    "# thry adding transperancy in the above example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(s=80, edgecolor=\"white\", linewidth=2.5) # Another way to define a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation with output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_target = abs(cor[\"MEDV\"]) #Selecting highly correlated features\n",
    "cor_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.5]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df[[\"MEDV\",\"LSTAT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.graphics.plot_grids as smg\n",
    "smg.scatter_ellipse(data,varnames=[\"MEDV\",\"LSTAT\"],level=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "sns.violinplot(data=df[[\"RM\",\"DIS\",\"LSTAT\"]], palette=\"Set3\", bw_method=0.2, cut=1, linewidth=1)\n",
    "ax.set(ylim=(0, 25))\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant column of ones, mandatory for sm.OLS model\n",
    "X_1 = sm.add_constant(X)\n",
    "X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting sm.OLS model\n",
    "model = sm.OLS(y,X_1).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(model.pvalues,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that the variable ‘AGE’ has highest pvalue of 0.9582293 which is greater than 0.05. Hence we will remove this feature and build the model once again. This is an iterative process and can be performed at once with the help of loop. This approach is implemented below, which would give the final set of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Elimination\n",
    "\n",
    "cols = list(X.columns)                                    # get a list of all columns in X\n",
    "pmax = 1\n",
    "\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[\"LSTAT\"]\n",
    "y=df[\"MEDV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(x)\n",
    "model = sm.OLS(y,X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,predictions,color='red',linewidth=5)\n",
    "plt.title('Boston House data')  \n",
    "plt.xlabel('LSTAT data')  \n",
    "plt.ylabel('MDEV data')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b\n",
    "- [Distance_correlation](https://en.wikipedia.org/wiki/Distance_correlation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
